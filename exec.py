from transform import *
from collections import Counter
import pandas as pd
from sets import Set

def checkCall(token,cnt,columnSet,missCol):
	if(token['type'] == 'INSTRUCTION' and token['name'] == 'call'):			#If the token correponds to a system call add it to the counter
		if '@' in token['operands'][0]:
			token['operands'][0] = token['operands'][0].replace("@","")
		if '?' in token['operands'][0]:
			token['operands'][0] = token['operands'][0].replace("?","")
		
		#Checks if multiple system calls are being made and seperates them
		if '$' in token['operands'][0]:
			procs = token['operands'][0].split('$')
			for call in procs:
				if len(call) > 7:
					if(call not in columnSet):				#If the item is not in set of colums add it
						missCol.append(call)
						columnSet.add(call)	
					cnt[call] += 1			
		else:
			if(token['operands'][0] not in columnSet):		#If the item is not in set of colums add it
				missCol.append(token['operands'][0])
				columnSet.add(token['operands'][0])
			cnt[token['operands'][0]] += 1

def removeExtraCols(df):
	X = list(df.columns.values)
	X.remove('Id')
	dropList = []
	count = 0
	for col in X:
		colLst = df[col].value_counts().index.tolist()
		colVal = list(df[col].value_counts())
		for i in range (0,len(colLst)):
			if colLst[i] == 0:
				if colVal[i] > 0.8*len(df):
					dropList.append(col)
					break
	df = df.drop(dropList,axis = 1)

output = pd.DataFrame(columns = ['Id'])						#Create DataFrame
outputSubmission = pd.read_csv("trainLabels.csv")			
count = 0													#Counter for index
dirs = outputSubmission.values
asmDirs = []												#list to store file names
classDir = []												#list to store class number corresponding to each asm file	
textSize = []												#list to store size of each asm file in bytes
columnSet = Set('Id')										#Set of columns encountered

for file in dirs:
	missCol = []
	temp = Counter()
	cnt = Counter()

	print "Current File is: ",file," File number: ",count+1
	
	#Clean the asm file
	#Result: opCode Arguments 
	cleanLines ,tSize= cleanASM(file[0])						
	textSize.append(tSize)
	
	for line in cleanLines:
		#Create token for each line in cleanLines
		token = tokenizer(line)
		if(token):
			temp[token['name']] += 1												#Increment count corresponding to opCode
			checkCall(token,cnt,columnSet,missCol)
			
	
	for item in temp:
		if temp[item] > 5:											#Add opCode intsructions to the counter iff their count is more than 5
			if(item not in columnSet):
				missCol.append(item)
				columnSet.add(item)
			cnt[item] = temp[item]


	temp = Counter()
	list_grams_procs = []
	for i, line in enumerate(cleanLines):							#Create 4Grams from cleanLines
		gram = join_grams(x = i, arr = cleanLines)
		if(gram != 69):
			temp[gram] += 1

	for item in temp:				
		if( temp[item] > 2):										#Add 4gram to the counter iff their count is more than 2
			if(item not in columnSet):
				missCol.append(item)
				columnSet.add(item)
			cnt[item] = temp[item]
		elif (item in columnSet):
			cnt[item] = temp[item]

	keys = []

	for item in missCol:											#Add missing columns in dataFrame and initialize them to zero
			output[item] = 0

	output.loc[count] = pd.Series(cnt)								#Add the keys and their corresponding 		

	asmDirs.append(file[0])	
	classDir.append(file[1])
	count += 1
output = removeExtraCols(output)
output['Id'] = asmDirs
output['TextSize'] = textSize
output['Class'] = classDir

output.fillna(0, inplace=True)
output.to_csv('allFeatures.csv', index = False)
